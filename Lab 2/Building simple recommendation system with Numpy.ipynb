{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "858de05e",
   "metadata": {},
   "source": [
    "# Lab 2: Recommendation System with Numpy\n",
    "In this Numpy exercise, the general requirement is not to use loops; I will specify where it is allowed\n",
    "\n",
    "(Last update: 12/11/2023)\n",
    "\n",
    "Name: Nguyễn Thị Minh Minh  \n",
    "Sdudent ID: 21127528\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bce3092",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceeaa165",
   "metadata": {},
   "source": [
    "## 1. Programming environment\n",
    "\n",
    "- You will re-use the Linux environment setup in Lab 0 - WarmUp. Don't forget to start your coding environment (`conda activate min_ds-env`) before doing your assignment.\n",
    "- Use Jupyter notebook or Jupyter lab, <font color=red>not Google Colab</font> (I can not grade you well on Google Colab) to edit your `*.ipynb` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "097d1336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Hp\\\\anaconda3\\\\python.exe'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbf9ded",
   "metadata": {},
   "source": [
    "- If there are no problems, the file to run python will be the file of the \"min_ds-env\" code environment.\n",
    "\n",
    "- In this article, you are not using the Pandas library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7b4612",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ce8fea",
   "metadata": {},
   "source": [
    "## 2. Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6630d75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# YOUR CODE HERE (OPTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b5f965",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116d0050",
   "metadata": {},
   "source": [
    "## 3. Data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e283245",
   "metadata": {},
   "source": [
    "Numpy is not a great library for handling operations like data reading and writing, but it's an excellent library for computational tasks. Therefore, in this article, we'll simply use the pre-collected dataset that I've attached in the folder of this lab. This dataset actually contains multiple files and is relatively large, but it has been curated to include relevant information for this lab. You can learn more about this dataset [here](https://www.kaggle.com/datasets/hernan4444/anime-recommendation-database-2020).\n",
    "\n",
    "Here is a specific description of the dataset:\n",
    ">The full dataset have the list of all animes register by the user with the respective score, watching status and numbers of episodes watched. This dataset contains 109 Million row, 17.562 different animes and 325.772 different users. The file have the following columns:\\\n",
    "1 - user_id: non identifiable randomly generated user id.\\\n",
    "2 - anime_id: MyAnemlist ID of the anime. (e.g. 1).\\\n",
    "3 - score: score between 1 to 10 given by the user. 0 if the user didn't assign a score. (e.g. 10)\\\n",
    "4 - watching_status: state ID from this anime in the anime list of this user. (e.g. 2)\\\n",
    "5 - watched_episodes: numbers of episodes watched by the user. (e.g. 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c46dd35",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d0554a",
   "metadata": {},
   "source": [
    "## 4. Data exploring & Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86a5001",
   "metadata": {},
   "source": [
    "### How many rows and columns does the data have?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b82236",
   "metadata": {},
   "source": [
    "Of course, the first thing you need to do is read the data file into the Numpy array and name it `user_ratings` (use function `np.genfromtxt`). You may encounter some minor problems with this task, it seems that all the data in the Numpy array is not what we want. This happens because the function `np.genfromtxt` has a default data type of `float`, you need to find a way to convert it to `uint64`. You should put the dataset file in the same directory as this notebook file to simplify when passing the file name to the function. Finally, you need to calculate the number of rows and columns for this dataset, these two values are stored in two variables `nrows` and `ncols` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ab3481b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "user_ratings = np.genfromtxt('anime.txt', delimiter = '\\t', dtype = 'uint64')\n",
    "nrows = user_ratings.shape[0]\n",
    "ncols = user_ratings.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "665c47a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 866,  138,    0,    6,    0],\n",
       "       [ 858,  696,    0,    6,    0],\n",
       "       [ 617,  147,    0,    6,    0],\n",
       "       [ 481, 1951,    8,    2,    3],\n",
       "       [ 890,  690,    6,    2,   26]], dtype=uint64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "assert user_ratings.dtype == np.uint64\n",
    "assert user_ratings.ndim == 2\n",
    "assert nrows == 66338\n",
    "assert ncols == 5\n",
    "user_ratings[:5] # Look at the first 5 lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35b930b",
   "metadata": {},
   "source": [
    "### Rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e554ab90",
   "metadata": {},
   "source": [
    "#### The meaning of each row\n",
    "\n",
    "Each row in the data set shows some information about a user's score for a anime."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bacd8d",
   "metadata": {},
   "source": [
    "#### Does the data have duplicate rows?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fb71b6",
   "metadata": {},
   "source": [
    "You will test this case and save the results to the `have_duplicated_rows` variable. This variable will have the value True if the data has duplicate lines and will have the value False otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "badd6cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "unique_rows, counts = np.unique(user_ratings, axis = 0, return_counts = True)\n",
    "have_duplicated_rows = np.any(counts > 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f1bffd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "assert have_duplicated_rows == False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c19f96d",
   "metadata": {},
   "source": [
    "Great, so there are no duplicate rows. Next we will explore the columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208d9f80",
   "metadata": {},
   "source": [
    "### Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625b73c3",
   "metadata": {},
   "source": [
    "#### The meaning of each column\n",
    "- The first column indicates the user's ID (user_ID)\n",
    "- The second column indicates the ID of the anime movie (anime_ID)\n",
    "- The third column shows the score at which the user rated the movie (ratings)\n",
    "- The fourth column indicates watching status (watching_status)\n",
    "- The fifth column indicates the episode watched (watched_episodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832ed6ab",
   "metadata": {},
   "source": [
    "#### What data type does each column currently have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f877453d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint64')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ratings.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4db741",
   "metadata": {},
   "source": [
    "At first glance, it seems that all columns are numeric. But in my opinion, the two columns `user_id` and `anime_id` should be classified into categorical groups. The reason for this is because both `user_id` and `anime_id` are simply identifiers and do not necessarily have an arithmetic relationship between the columns. Of course, this is just an objective perspective and not true for all cases, but to make it easier to work, in this lab we will agree with the above thought."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813f3930",
   "metadata": {},
   "source": [
    "#### For each column with numeric datatype, how are the values distributed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34421ec3",
   "metadata": {},
   "source": [
    "First, we need to see how many missing values the numeric columns have. This mission is quite 'difficult' ^^ so I will do it for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1bc561a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.isnan(user_ratings[:, 2:]), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c090a7b8",
   "metadata": {},
   "source": [
    "Great, so all numeric columns don't have any missing values.\n",
    "\n",
    "Now, your job is to calculate the min, Q1(25%), median, Q3(75%) and max of these numeric columns. You will need to use the `np.percentile` function to do this. Then, the all values of each column are saved respectively into 3 Numpy arrays namely `rating_percentile`, `status_percentile`, `episodes_percentile`. Also, make sure that these Numpy arrays all have the `uint64` data type so you don't get into trouble with the TEST cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a4cfdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "calculated_columns = [2,3,4]\n",
    "\n",
    "min_val = np.min(user_ratings[:, calculated_columns], axis=0)\n",
    "q1_25 = np.percentile(user_ratings[:, calculated_columns],25, axis=0)\n",
    "median_val = np.median(user_ratings[:, calculated_columns], axis=0)\n",
    "q3_75 = np.percentile(user_ratings[:, calculated_columns],75, axis=0)\n",
    "max_val = np.max(user_ratings[:, calculated_columns], axis=0)\n",
    "\n",
    "rating_percentile = np.array([min_val[0], q1_25[0], median_val[0], q3_75[0], max_val[0]], dtype = 'uint64')\n",
    "status_percentile = np.array([min_val[1], q1_25[1], median_val[1], q3_75[1], max_val[1]], dtype = 'uint64')\n",
    "episodes_percentile = np.array([min_val[2], q1_25[2], median_val[2], q3_75[2], max_val[2]], dtype = 'uint64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ccf440b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "assert np.array_equal(rating_percentile, np.array([0, 0, 5, 8, 10]))\n",
    "assert np.array_equal(status_percentile, np.array([1, 2, 2, 6, 6]))\n",
    "assert np.array_equal(episodes_percentile, np.array([0, 0, 1, 24, 36600]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1542f3da",
   "metadata": {},
   "source": [
    "#### For each column with categorical datatype, how are the values distributed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a708fc2",
   "metadata": {},
   "source": [
    "Just like with numeric columns, we need to see if two categorical columns have missing values? (This is difficult so let me do it for you :v )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41aeae4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.isnan(user_ratings[:, :2]), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7746f1",
   "metadata": {},
   "source": [
    "Your task is to, for each column, calculate a list of 5 numbers: the number of distinct values, the value that appears least with its corresponding count (total of 2 numbers), and the value that appears most with its corresponding count (total of 2 numbers). You should store the 2 lists calculated for 2 columns in two variables, namely `user_profile` and `anime_profile`. If multiple users rate the least number of movies, we will agree to choose the user with the smallest id. And vice versa, if many users rate the most movies, we will choose the user with the largest id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "464c0ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "unique_users, count_unique_users = np.unique(user_ratings[:,0], return_counts = True)\n",
    "user_rate_least = unique_users[count_unique_users == np.min(count_unique_users)][0]\n",
    "user_rate_highest =  unique_users[count_unique_users == np.max(count_unique_users)][0]\n",
    "user_profile = np.array([len(unique_users), user_rate_least, np.min(count_unique_users), user_rate_highest, np.max(count_unique_users)], dtype = 'uint64')\n",
    "user_profile = user_profile.tolist()\n",
    "\n",
    "unique_anime, count_unique_anime = np.unique(user_ratings[:,1], return_counts = True)\n",
    "movie_rate_least = unique_anime[count_unique_anime == np.min(count_unique_anime)][0]\n",
    "movie_rate_highest = unique_anime[count_unique_anime == np.max(count_unique_anime)][0]\n",
    "anime_profile = np.array([len(unique_anime), movie_rate_least, np.min(count_unique_anime), movie_rate_highest, np.max(count_unique_anime)], dtype = 'uint64')\n",
    "anime_profile = anime_profile.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "742cbc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert user_profile == [898, # Có chừng này user\n",
    "                        31,  # Đây là user rate ít movie nhất\n",
    "                        1,  # và đó là chừng này movie\n",
    "                        890, # Đây là user rate nhiều movie nhất\n",
    "                        1138] # và đó là chừng này movie\n",
    "assert anime_profile == [1801,#Có chừng này movie\n",
    "                         115, #Đây là movie được ít user rate nhất\n",
    "                         1,   #và đó là chừng này user\n",
    "                         1535,  #Đây là movie được nhiều user rate nhất\n",
    "                         701] #và đó là chừng này user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02cefe4",
   "metadata": {},
   "source": [
    "Incidentally, we need to check the maximum and minimum values of the two columns `user_id` and `anime_id`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be8889db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User id  - min & max: 0 & 1000\n",
      "Anime id - min & max: 1 & 2000\n"
     ]
    }
   ],
   "source": [
    "print('User id  - min & max:', \n",
    "      user_ratings[:, 0].min(), '&', user_ratings[:, 0].max()) \n",
    "print('Anime id - min & max:', \n",
    "      user_ratings[:, 1].min(), '&', user_ratings[:, 1].max()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c3fbca",
   "metadata": {},
   "source": [
    "\"It can be observed that for `user_id`, there is nothing unusual, but for `anime_id`, the first anime is numbered from 1 instead of 0 like `user_id`. Although this is not a significant issue, for convenience in the subsequent implementation, we need to normalize the `anime_id` column.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6cdf8f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ratings[:, 1] = user_ratings[:, 1] -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e0cff7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22b5c3a",
   "metadata": {},
   "source": [
    "## 5. Question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00e8647",
   "metadata": {},
   "source": [
    "The previous section was just to warm you up before diving into the main content of this lab. Now, we have a bit better understanding of the dataset. We will attempt to pose meaningful questions and find answers using the data.\n",
    "\n",
    "One interesting question to ask is: *For each different user, is it possible to recommend animes that the user has never watched before?*\n",
    "\n",
    "Finding an answer to this question can be beneficial for both users and movie streaming service providers:\n",
    "- Users: Users may want to watch a movie, but with so many options available, they may not know which one to choose. It would be convenient for users if the system could suggest a list of movies that they are likely to enjoy.\n",
    "- Movie Streaming Service Providers: If the system makes good recommendations, it's more likely that users will watch and enjoy the movies. This, in turn, means users will continue to pay for the service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a76fc7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfd9472",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece65a3d",
   "metadata": {},
   "source": [
    "First, we need to decide which information to use in building the anime recommendation system. Obviously, the columns `user_id`, `anime_id`, and `rating` are essential to perform this task. As for the two columns `watching_status` and `watched_episodes`, these columns can still have value in practice when building a recommendation model. However, for simplicity, we will temporarily set aside these two columns here.\n",
    "\n",
    "Based on 3 columns, you need to create a 2D NumPy matrix named `ratings_mat`. In this matrix, the number of rows represents the number of users, while the number of columns represents the number of anime. So, `ratings_mat[i, j]` will represent the rating that `user_i` has given to `anime_j`. \"For anime series that the user has not rated, the value will be 'NaN'.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3974d25f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9819275724275724"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # YOUR CODE HERE\n",
    "# # raise NotImplementedError()\n",
    "users_num = (user_ratings[:,0].max() + 1).astype(int) #count from 0\n",
    "anime_num = (user_ratings[:,1].max() + 1).astype(int)\n",
    "ratings_mat = np.full((users_num, anime_num), np.nan)\n",
    "\n",
    "user_indices, anime_indices, rating_scores = user_ratings[:,:3].T\n",
    "rating_scores = rating_scores.astype(float)\n",
    "\n",
    "rating_scores[rating_scores == 0] = np.nan\n",
    "\n",
    "ratings_mat[user_indices, anime_indices] = rating_scores\n",
    "\n",
    "missing_ratios = np.isnan(ratings_mat).sum()/ ratings_mat.size\n",
    "missing_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6822489c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ratings_mat.shape == (1001, 2000)\n",
    "missing_ratios = np.mean(np.isnan(ratings_mat))\n",
    "assert missing_ratios.round(3) == 0.982"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e34a223",
   "metadata": {},
   "source": [
    "### Analyze data to answer the question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283e379f",
   "metadata": {},
   "source": [
    "It would be much simpler if we used algorithms supported by other libraries. However, the main goal of this lab is to help you practice using the Numpy library. Therefore, you will have the opportunity to build a simple anime recommendation system from scratch using the provided data, utilizing only Numpy library. Please remember that Numpy doesn't favor loops, so you are only allowed to use loops where I explicitly permit.\n",
    "\n",
    "In my opinion, there are two fundamental tasks in a anime recommendation system:\n",
    "\n",
    "- First, you need to predict the ratings for animes that a user hasn't reviewed or watched yet.\n",
    "- Second, you need to provide recommendations to users based on the top-rated animes that have been predicted.\n",
    "\n",
    "It seems that the second task will become much simpler if we can accomplish the first task. One of the simplest ways to tackle task 1 is by computing the similarity between users and using this similarity to make predictions. However, there are some considerations to keep in mind. It's not feasible to compute similarity between all users at once, as it might lead to memory issues (even if you have enough memory, my computer is quite limited in that regard :<). One way to address this issue is to process a group of users at a time, referred to as `a batch`. To keep it simple, let's stick with a `batch_size = 32`, which I believe is a reasonable value. You should try to make your code work with a single batch first and then extend it to process all batches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b62778",
   "metadata": {},
   "source": [
    "\"First, you will try with a batch corresponding to users with indices from `start` to `end`.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "701e8fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "start = 0\n",
    "end = batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbdc6fd",
   "metadata": {},
   "source": [
    "Step 1: Calculate the `similarities` array to show the similarity between each user in the current batch with all users in the entire dataset. This array will have a size of `batch_size` x `n_users` (`n_users` is the total number of users in the dataset), where `similarities[i, j]` indicates the similarity between `user_i` and `user_j`. In the case where two users have no common rated movies (when running, you may see a warning 'RuntimeWarning: Mean of empty slice'), you set the similarity to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d751cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_18672\\3518680953.py:10: RuntimeWarning: Mean of empty slice\n",
      "  similarities = np.nanmean(rating_difference, axis = 2)\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "np.set_printoptions(suppress = True)\n",
    "n_users = ratings_mat.shape[0]\n",
    "n_movies = ratings_mat.shape[1]\n",
    "\n",
    "def calculate_similarities(ratings, start, end):\n",
    "    batch_arr = ratings[start:end, :]\n",
    "    rating_difference = np.abs(batch_arr[:, np.newaxis] - ratings)\n",
    "    similarities = np.nanmean(rating_difference, axis = 2)\n",
    "    similarities = 1/(similarities + 0.001)\n",
    "    similarities[np.isnan(similarities)] = 0\n",
    "    return similarities\n",
    "\n",
    "similarities = calculate_similarities(ratings_mat, start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1720a328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "assert similarities.shape == (32, 1001)\n",
    "assert np.array_equal(similarities[:3, :3].round(1), \n",
    "                      np.array([[1.0e+03, 6.0e-01, 2.0e+00],\n",
    "                                [6.0e-01, 1.0e+03, 1.5e+00],\n",
    "                                [2.0e+00, 1.5e+00, 1.0e+03]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f582808",
   "metadata": {},
   "source": [
    "Step 2: calculate the `weights` matrix. The array `weights` will have the size `batch_size` x `n_users` x `n_movies` (where `n_movies` is the total number of movies). About how to calculate `weights`, you can refer to file `example.ipynb`.\n",
    "\n",
    "When running, you will see the warning \"RuntimeWarning: invalid value encountered in true_divide\"; This is because the users who rate a movie under consideration all have a similarity of 0 with a user under review, resulting in normalization to 0/0 and the result is difficult. This case means there is not enough information to predict the score and in this article, you should leave it as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "766f776f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_18672\\1905569264.py:11: RuntimeWarning: invalid value encountered in divide\n",
      "  weights = weights/np.nansum(weights,axis = 1, keepdims = True)\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "def calculate_weights(start, end, similarities, batch_size):\n",
    "    rating_batch = np.empty((batch_size, n_users, n_movies))\n",
    "    batch_arr = ratings_mat[start:end, :]\n",
    "    ratings_mark = np.isnan(batch_arr)\n",
    "    ratings_mark = np.repeat(ratings_mark[:, np.newaxis], n_users, axis=1)\n",
    "    indices_mark = np.where(ratings_mark == True)\n",
    "    rating_batch[indices_mark] = ratings_mat[indices_mark[1], indices_mark[2]]\n",
    "    weights = ~np.isnan(rating_batch) * similarities[:,:,np.newaxis]\n",
    "    weights = weights/np.nansum(weights,axis = 1, keepdims = True)\n",
    "    return weights\n",
    "\n",
    "weights = calculate_weights(start, end, similarities, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0180000d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "assert weights.shape == (32, 1001, 2000)\n",
    "assert np.sum(np.isnan(weights)) == 16462446"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5249bfb0",
   "metadata": {},
   "source": [
    "Step 3: For each user in the batch under consideration, calculate the score (for all movies) by multiplying the score of all users with the corresponding weight in the `weight` array; then write each user's scores down to one line in the `filled_ratings` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59f6ba0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_ratings = np.empty_like(ratings_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c8a2d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "def calculate_filled_ratings(ratings, weights):\n",
    "    filled_ratings = np.nansum(ratings * weights, axis = 1)\n",
    "    return filled_ratings\n",
    "    \n",
    "filled_ratings = calculate_filled_ratings(ratings_mat, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c84b5f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "filled_batch = filled_ratings[start:end]\n",
    "filled_nanvals = filled_batch[np.isnan(ratings_mat[start:end])]\n",
    "assert np.array_equal(filled_nanvals[:3].round(1),\n",
    "                      np.array([8.6, 0. , 0. ]))\n",
    "assert np.array_equal(filled_nanvals[-3:].round(1),\n",
    "                      np.array([0., 0., 0.]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f558f3",
   "metadata": {},
   "source": [
    "Great ! So your code has run on a batch, now it's time for you to use the `for` loop to cycle through all the batches in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ea23646",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_18672\\3518680953.py:10: RuntimeWarning: Mean of empty slice\n",
      "  similarities = np.nanmean(rating_difference, axis = 2)\n",
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_18672\\1905569264.py:11: RuntimeWarning: invalid value encountered in divide\n",
      "  weights = weights/np.nansum(weights,axis = 1, keepdims = True)\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "def process_ratings(batch_size = 2):\n",
    "    batch_num = int(np.ceil(n_users/batch_size))\n",
    "    return_ratings = np.empty_like(ratings_mat)\n",
    "    for i in range(batch_num):\n",
    "        start = i*batch_size\n",
    "        end = start + batch_size\n",
    "        if end > n_users:\n",
    "            end = n_users\n",
    "            batch_size = end - start\n",
    "        similarities = calculate_similarities(ratings_mat, start, end)\n",
    "        weights = calculate_weights(start, end, similarities, batch_size)\n",
    "        filled_ratings_mat = calculate_filled_ratings(ratings_mat, weights)\n",
    "        return_ratings[start:end, :] = filled_ratings_mat\n",
    "    return return_ratings\n",
    "\n",
    "filled_ratings = process_ratings(batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "063f85c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "filled_nanvals = filled_ratings[np.isnan(ratings_mat)]\n",
    "assert np.array_equal(filled_nanvals[:3].round(1),\n",
    "                      np.array([8.6, 0. , 0. ]))\n",
    "assert np.array_equal(filled_nanvals[-3:].round(1),\n",
    "                      np.array([5.7, 5. , 6.6]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
